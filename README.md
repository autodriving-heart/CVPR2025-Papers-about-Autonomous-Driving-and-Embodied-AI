# CVPR 2025-Papers-about-Autonomous-Driving-and-Embodied-AI

## Autonomous-Driving

### (1)Occupancy

**UniScene: Unified Occupancy-centric Driving Scene Generation**

- paper: https://arxiv.org/pdf/2412.05435

- code: https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation

### (2)End-to-End Autonomous-Driving

**Don't Shake the Wheel: Momentum-AwarePlanning in End-to-End Autonomous Driving**

- paper: https://arxiv.org/pdf/2503.03125

- code: https://github.com/adept-thu/MomAD

**DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving**

- paper: https://arxiv.org/pdf/2411.15139

- code: https://github.com/hustvl/DiffusionDrive

### (3)Multi-modal Fusion

**V2X - R: Cooperative LiDAR - 4D Radar Fusion with Denoising Diffusion for 3D Object Detection**

- paper: https://arxiv.org/pdf/2411.08402

- code: https://github.com/ylwhxht/V2X-R

### (4)Vision Language Model

**OmniDrive: A Holistic Vision - Language Dataset for Autonomous Driving with counter Factual Reasoning**

- paper: https://arxiv.org/pdf/2405.01533

- code: https://github.com/NVlabs/OmniDrive

### (5)World Model

**DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene**

- paper: https://arxiv.org/pdf/2410.13571

- code: https://github.com/GigaAI-research/DriveDreamer4D

**ReconDreamer: Crafting World Models for Driving Scene Reconstruction via Online Restoration**

- paper: https://arxiv.org/pdf/2411.19548

- code: https://github.com/GigaAI-research/ReconDreamer

### (6)Closed Loop

**DrivingSphere: Building a High-fidelity 4D World for Closed-loop Simulation**

- paper: https://arxiv.org/abs/2411.11252

- code: https://github.com/yanty123/DrivingSphere

### (7)Lane Detection

**Rethinking Lanes and Points in complex Scenarios for Monocular 3D Lane Detection**

- paper: https://arxiv.org/abs/2503.06237

## Embodied-AI

**DexHandDiff: Interaction - aware Diffusion Planning for Adaptive Dexterous Manipulation**

- paper: https://arxiv.org/abs/2411.18562

**G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation**

- paper: https://arxiv.org/abs/2411.18369
- code:  https://github.com/TianxingChen/G3Flow

**RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins**

- paper: https://arxiv.org/abs/2409.02920
- code: https://github.com/TianxingChen/RoboTwin?tab=readme-ov-file#robotwin-dual-arm-robot-benchmark-with-generative-digital-twins

**Code-as-Monitor: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection**

- paper: https://arxiv.org/abs/2412.04455

## Others

**Mamba4D: Efficient 4D Point Cloud Video Understanding with Disentangled Spatial-Temporal State Space Models**

- paper: https://arxiv.org/abs/2405.14338

- code: https://github.com/IRMVLab/Mamba4D

**Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model**

- paper: https://arxiv.org/abs/2411.19108

- code: https://github.com/ali-vilab/TeaCache

**DynRefer: Delving into Region-level Multi-modality Tasks via Dynamic Resolution**

- paper: https://arxiv.org/abs/2405.16071

- code: https://github.com/callsys/DynRefer

**OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations**

- paper: https://arxiv.org/pdf/2412.07626

- code: https://arxiv.org/pdf/2412.07626
