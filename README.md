# CVPR 2025-Papers-about-Autonomous-Driving-and-Embodied-AI

## Autonomous-Driving

### (1) Occupancy

**UniScene: Unified Occupancy-centric Driving Scene Generation**

- paper: https://arxiv.org/pdf/2412.05435

- code: https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation
  
**GaussianFormer-2: Probabilistic Gaussian Superposition for Efficient 3D Occupancy Prediction**

- paper: https://arxiv.org/abs/2412.04384

- code: https://github.com/huang-yh/GaussianFormer

### (2) End-to-End Autonomous-Driving

**Don't Shake the Wheel: Momentum-AwarePlanning in End-to-End Autonomous Driving**

- paper: https://arxiv.org/pdf/2503.03125

- code: https://github.com/adept-thu/MomAD

**DiffusionDrive: Truncated Diffusion Model for End-to-End Autonomous Driving**

- paper: https://arxiv.org/pdf/2411.15139

- code: https://github.com/hustvl/DiffusionDrive

### (3) Multi-modal Fusion

**V2X - R: Cooperative LiDAR - 4D Radar Fusion with Denoising Diffusion for 3D Object Detection**

- paper: https://arxiv.org/pdf/2411.08402

- code: https://github.com/ylwhxht/V2X-R

### (4) Vision Language Model

**OmniDrive: A Holistic Vision - Language Dataset for Autonomous Driving with counter Factual Reasoning**

- paper: https://arxiv.org/pdf/2405.01533

- code: https://github.com/NVlabs/OmniDrive

### (5) World Model

**DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene**

- paper: https://arxiv.org/pdf/2410.13571

- code: https://github.com/GigaAI-research/DriveDreamer4D

**ReconDreamer: Crafting World Models for Driving Scene Reconstruction via Online Restoration**

- paper: https://arxiv.org/pdf/2411.19548

- code: https://github.com/GigaAI-research/ReconDreamer

### (6) Closed Loop

**DrivingSphere: Building a High-fidelity 4D World for Closed-loop Simulation**

- paper: https://arxiv.org/abs/2411.11252

- code: https://github.com/yanty123/DrivingSphere

### (7) Lane Detection

**Rethinking Lanes and Points in complex Scenarios for Monocular 3D Lane Detection**

- paper: https://arxiv.org/abs/2503.06237

### (8) Motion Prediction

**ModeSeq: Taming Sparse Multimodal Motion Prediction with Sequential Mode Modeling**

- paper: https://arxiv.org/pdf/2411.11911

## Embodied-AI

### (1) Diffusion Model

**DexHandDiff: Interaction - aware Diffusion Planning for Adaptive Dexterous Manipulation**

- paper: https://arxiv.org/abs/2411.18562

### (2) 3D Semantic Flow

**G3Flow: Generative 3D Semantic Flow for Pose-aware and Generalizable Object Manipulation**

- paper: https://arxiv.org/abs/2411.18369
- code:  https://github.com/TianxingChen/G3Flow

### (3) Dual-Arm Robot

**RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins**

- paper: https://arxiv.org/abs/2409.02920
- code: https://github.com/TianxingChen/RoboTwin?tab=readme-ov-file#robotwin-dual-arm-robot-benchmark-with-generative-digital-twins

**Towards Long-Horizon Vision-Language Navigation: Platform, Benchmark and Method**

- paper: https://arxiv.org/pdf/2412.09082
- code: https://github.com/HCPLab-SYSU/LH-VLN
- 
### (4) Visual Language Model

**Code-as-Monitor: Constraint-aware Visual Programming for Reactive and Proactive Robotic Failure Detection**

- paper: https://arxiv.org/abs/2412.04455

**PhysVLM: Enabling Visual Language Models to Understand Robotic Physical Reachability**

--paper: https://arxiv.org/abs/2503.08481

## Others

**Mamba4D: Efficient 4D Point Cloud Video Understanding with Disentangled Spatial-Temporal State Space Models**

- paper: https://arxiv.org/abs/2405.14338

- code: https://github.com/IRMVLab/Mamba4D

**Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model**

- paper: https://arxiv.org/abs/2411.19108

- code: https://github.com/ali-vilab/TeaCache

**DynRefer: Delving into Region-level Multi-modality Tasks via Dynamic Resolution**

- paper: https://arxiv.org/abs/2405.16071

- code: https://github.com/callsys/DynRefer

**OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations**

- paper: https://arxiv.org/pdf/2412.07626

- code: https://arxiv.org/pdf/2412.07626

**VTON360: High-Fidelity Virtual Try-On from Any Viewing Direction**

- paper: https://arxiv.org/abs/2503.12165

- code: https://github.com/scnuhealthy/VTON360

**Cross-modal Causal Relation Alignment for Video Question Grounding**

-- paper: https://arxiv.org/abs/2503.07635

-- code: https://github.com/WissingChen/CRA-GQA

**DSPNet: Dual-vision Scene Perception for Robust 3D Question Answering**

-- paper: https://arxiv.org/abs/2503.03190

-- code: https://github.com/LZ-CH/DSPNet

**Reproducible Vision-Language Models Meet Concepts Out of Pre-Training**

**LLM-driven Multimodal and Multi-Identity Listening Head Generation**

**DAGSM: Disentangled Avatar Generation with GS-enhanced Mesh**

-- paper: https://arxiv.org/abs/2411.15205

**HiRes-LLaVA: Restoring Fragmentation Input in High-Resolution Large Vision-Language Models**

-- paper: https://arxiv.org/abs/2407.08706

**FireEdit: Fine-grained Instruction-based Image Editing via Region-aware Vision Language Model**

-- paper: https://arxiv.org/abs/2503.19839

-- code: https://zjgans.github.io/fireedit.github.io/

**EMOVA: Empowering Language Models to See, Hear and Speak with Vivid Emotions**

-- paper: https://arxiv.org/abs/2409.18042

-- code: https://emova-anonymous.github.io/

**PS-Diffusion: Photorealistic Subject-Driven Image Editing with Disentangled Control and Attention**

**Boosting the Dual-Stream Architecture in Ultra-High Resolution Segmentation with Resolution-Biased Uncertainty Estimation**

**No Pains, More Gains: Recycling Sub-Salient Patches for Efficient High-Resolution Image Recognition**

**Empowering Large Language Models with 3D Situation Awareness**

-- paper: https://arxiv.org/abs/2503.23024

**Rethinking Query-based Transformer for Continual Image Segmentation**

**Eval3D: Interpretable and Fine-grained Evaluation for 3D Generation**

- paper: http://arxiv.org/pdf/2504.18509v1

- code: https://eval3d.git

**Seeing Soundscapes: Audio-Visual Generation and Separation from Soundscapes Using Audio-Visual Separator**

- paper: http://arxiv.org/pdf/2504.18283v1

**SSL4Eco: A Global Seasonal Dataset for Geospatial Foundation Models in Ecology**

- paper: http://arxiv.org/pdf/2504.18256v1

- code: https://github.com/PlekhanovaElena/ssl4eco

**BiasBench: A reproducible benchmark for tuning the biases of event cameras**

- paper: http://arxiv.org/pdf/2504.18235v1

**Enhancing Privacy-Utility Trade-offs to Mitigate Memorization in Diffusion Models**

- paper: http://arxiv.org/pdf/2504.18032v1

- code: https://chenchen-usyd.git

**Dynamic Camera Poses and Where to Find Them**

- paper: http://arxiv.org/pdf/2504.17788v1

- code: https://research.nvidia.com/labs/dir/dynpose-100k

**PICO: Reconstructing 3D People In Contact with Objects**

- paper: http://arxiv.org/pdf/2504.17695v1

- code: https://pico.is.tue.mpg.de

**VEU-Bench: Towards Comprehensive Understanding of Video Editing**

- paper: http://arxiv.org/pdf/2504.17828v1

**Dual Prompting Image Restoration with Diffusion Transformers**

- paper: http://arxiv.org/pdf/2504.17825v1

**SemanticSugarBeets: A Multi-Task Framework and Dataset for Inspecting Harvest and Storage Characteristics of Sugar Beets**

- paper: http://arxiv.org/pdf/2504.16684v1

- code: https://github.com/semanticsugarbeets/semanticsugarbeets

**PRaDA: Projective Radial Distortion Averaging**

- paper: http://arxiv.org/pdf/2504.16499v1

**CLOC: Contrastive Learning for Ordinal Classification with Multi-Margin N-pair Loss**

- paper: http://arxiv.org/pdf/2504.17813v1

**LiveCC: Learning Video LLM with Streaming Speech Transcription at Scale**

- paper: http://arxiv.org/pdf/2504.16030v1

- code: https://showlab.git

**PointLoRA: Low-Rank Adaptation with Token Selection for Point Cloud Learning**

- paper: http://arxiv.org/pdf/2504.16023v1

- code: https://github.com/songw-zju/PointLoRA

**RepNet-VSR: Reparameterizable Architecture for High-Fidelity Video Super-Resolution**

- paper: http://arxiv.org/pdf/2504.15649v1

**MirrorVerse: Pushing Diffusion Models to Realistically Reflect the World**

- paper: http://arxiv.org/pdf/2504.15397v1

- code: https://mirror-verse.git

**Plug-and-Play Versatile Compressed Video Enhancement**

- paper: http://arxiv.org/pdf/2504.15380v1

- code: https://huimin-zeng.git

**Acquire and then Adapt: Squeezing out Text-to-Image Model for Image Restoration**

- paper: http://arxiv.org/pdf/2504.15159v1

**Improving Sound Source Localization with Joint Slot Attention on Image and Audio**

- paper: http://arxiv.org/pdf/2504.15118v1

**NTIRE 2025 Challenge on Short-form UGC Video Quality Assessment and Enhancement: KwaiSR Dataset and Study**

- paper: http://arxiv.org/pdf/2504.15003v1

- code: https://lixinustc.git

**DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in Fine-Grained Visual Understanding**

- paper: http://arxiv.org/pdf/2504.14920v1

- code: https://github.com/PKU-ICST-MIPL/DyFo_CVPR2025
